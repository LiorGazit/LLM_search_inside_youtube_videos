{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA3qEn5YlzJc"
      },
      "source": [
        "# Summarize, translate, and edit a Ted Talk from Youtube video by asking the LLM\n",
        "By [Lior Gazit](https://www.linkedin.com/in/liorgazit/)  \n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/LiorGazit/LLM_search_inside_youtube_videos/blob/main/Summarize_translate_and_edit_a_TedTalk_video_by_asking_the_LLM.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "**Description of the notebook:**  \n",
        "Pick a Youtube video that you'd like to summarize and edit to your liking without having to spend the time to watch all of it.\n",
        "In this notebook I picked one of the popular Ted Talks, summarized it, translated it to Russian, and edited it some more.  \n",
        "\n",
        "**Requirements:**  \n",
        "* Open this notebook in a free [Google Colab instance](ttps://colab.research.google.com/github/LiorGazit/LLM_search_inside_youtube_videos/blob/main/Summarize_translate_and_edit_a_TedTalk_video_by_asking_the_LLM.ipynb).  \n",
        "* This code picks OpenAI's API as a choice of LLM, so a paid **API key** is necessary.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VQE9nGwDaiG"
      },
      "source": [
        "Install:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtqSnCgwDDCg"
      },
      "outputs": [],
      "source": [
        "%pip -q install youtube-transcript-api\n",
        "%pip -q install openai\n",
        "%pip -q install numpy\n",
        "%pip -q install pytube\n",
        "%pip -q install faiss-cpu\n",
        "%pip -q install tiktoken\n",
        "%pip -q install textwrap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrrlU4QqDmxl"
      },
      "source": [
        "Imports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ohPMkz4zDqxz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "import faiss\n",
        "import numpy as np\n",
        "import openai\n",
        "import tiktoken\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "import textwrap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAO_SzlyDr5x"
      },
      "source": [
        "#### Insert API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyRo07nqD08l"
      },
      "outputs": [],
      "source": [
        "my_api_key = \"...\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7aBp5OZsmy7"
      },
      "source": [
        "#### Save API Key to Environement Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "isN0JA6ksm__"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = my_api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-lR8B_Us4FT"
      },
      "source": [
        "#### Pick the Youtube Video and Insert its URL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y1LSH25XnbVA"
      },
      "outputs": [],
      "source": [
        "video_url = \"https://www.youtube.com/watch?v=q-7zAkwAOYg&ab_channel=TEDxTalks\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Define functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract video ID from URL\n",
        "def extract_video_id(url):\n",
        "    query = urlparse(url).query\n",
        "    params = parse_qs(query)\n",
        "    return params['v'][0]\n",
        "\n",
        "# Fetch transcript using youtube-transcript-api\n",
        "def get_transcript(video_url):\n",
        "    video_id = extract_video_id(video_url)\n",
        "    transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\n",
        "    text = ' '.join([t['text'] for t in transcript])\n",
        "    return text\n",
        "\n",
        "# Split transcript into chunks\n",
        "def split_chunks(transcript, max_tokens=500):\n",
        "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    words = transcript.split()\n",
        "    chunks, current_chunk = [], []\n",
        "\n",
        "    for word in words:\n",
        "        current_chunk.append(word)\n",
        "        if len(encoding.encode(' '.join(current_chunk))) > max_tokens:\n",
        "            current_chunk.pop()\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "            current_chunk = [word]\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "    return chunks\n",
        "\n",
        "# Get embeddings using updated OpenAI embeddings model\n",
        "def get_embeddings(chunks, model=\"text-embedding-3-small\"):\n",
        "    embeddings = openai.embeddings.create(\n",
        "        input=chunks,\n",
        "        model=model\n",
        "    )\n",
        "    embeddings_list = [e.embedding for e in embeddings.data]\n",
        "    return np.array(embeddings_list, dtype='float32')\n",
        "\n",
        "# Build FAISS index\n",
        "def build_index(embeddings):\n",
        "    dim = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dim)\n",
        "    index.add(embeddings)\n",
        "    return index\n",
        "\n",
        "# Similarity search\n",
        "def search_chunks(question, chunks, index, top_k=3):\n",
        "    query_embedding = openai.embeddings.create(\n",
        "        input=[question],\n",
        "        model=\"text-embedding-3-small\"\n",
        "    ).data[0].embedding\n",
        "    query_embedding = np.array([query_embedding], dtype='float32')\n",
        "\n",
        "    _, indices = index.search(query_embedding, top_k)\n",
        "    return [chunks[i] for i in indices[0]]\n",
        "\n",
        "# Query LLM with retrieved context using the latest GPT-4 model\n",
        "def query_llm(prompt, model=\"gpt-4-turbo\"):\n",
        "    completion = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You answer questions based on video transcripts. Drop a new line after every sentence!\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.5,\n",
        "        max_tokens=1000\n",
        "    )\n",
        "    return completion.choices[0].message.content.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set Up the Retrieval Mechanism:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entire pipeline execution\n",
        "def pipeline(video_url, question):\n",
        "    print(\"--- Prompt ---\\n\")\n",
        "    print(question)\n",
        "\n",
        "    # Fetching transcript:\n",
        "    transcript = get_transcript(video_url)\n",
        "\n",
        "    # Splitting transcript into chunks:\n",
        "    chunks = split_chunks(transcript)\n",
        "\n",
        "    # Getting embeddings:\n",
        "    embeddings = get_embeddings(chunks)\n",
        "\n",
        "    # Building FAISS index:\n",
        "    index = build_index(embeddings)\n",
        "\n",
        "    # Searching relevant chunks:\n",
        "    relevant_chunks = search_chunks(question, chunks, index)\n",
        "\n",
        "    context = \"\\n\\n\".join(relevant_chunks)\n",
        "    prompt = f\"Context from video:\\n\\n{context}\\n\\nQuestion: {question}\\nStart a new line after every sentence in your answer!\"\n",
        "\n",
        "    print(\"\\n--- Answer ---\\n\")\n",
        "    return query_llm(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summarizing the content of the video and translating to different languages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Prompt ---\n",
            "\n",
            "Please review the entire content, summarize it to the length of 4 sentence, then translate it to Russian.\n",
            "Make sure the summary is consistent with the content.\n",
            "Put the string '----' between the English part of the answer and the Russian part.\n",
            "\n",
            "--- Answer ---\n",
            "\n",
            "The Harvard Study of Adult Development, spanning\n",
            "75 years and involving 724 men, reveals that good\n",
            "relationships are key to happiness and health, not\n",
            "wealth or fame. The study found that social\n",
            "connections improve physical health and increase\n",
            "longevity, while loneliness has the opposite\n",
            "effect. Quality, not quantity, of relationships\n",
            "matters, with supportive environments proving\n",
            "beneficial and high-conflict situations being\n",
            "detrimental to health. The study’s strongest\n",
            "predictor of a happy, healthy old age was\n",
            "satisfaction in relationships at age 50. ----\n",
            "Гарвардское исследование взрослой жизни,\n",
            "продолжавшееся 75 лет и охватившее 724 мужчин,\n",
            "показывает, что хорошие отношения являются ключом\n",
            "к счастью и здоровью, а не богатство или слава.\n",
            "Исследование показало, что социальные связи\n",
            "улучшают физическое здоровье и увеличивают\n",
            "продолжительность жизни, в то время как\n",
            "одиночество имеет противоположный эффект. Важно не\n",
            "количество отношений, а их качество, при этом\n",
            "поддерживающая среда оказывается полезной, а\n",
            "конфликтные ситуации вредны для здоровья. Самым\n",
            "сильным предиктором счастливой и здоровой старости\n",
            "было удовлетворение отношениями в возрасте 50 лет.\n"
          ]
        }
      ],
      "source": [
        "question = \"\"\"Please review the entire content, summarize it to the length of 4 sentence, then translate it to Russian.\n",
        "Make sure the summary is consistent with the content.\n",
        "Put the string '----' between the English part of the answer and the Russian part.\"\"\"\n",
        "\n",
        "original_answer = pipeline(video_url, question)\n",
        "\n",
        "print(textwrap.fill(original_answer, width=50, replace_whitespace=True).replace(\"\\\\n \", \"\\n\\n\").replace(\"---- \", \"\\n\\nRussian:\\n\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYMW2pItnbcj",
        "outputId": "4d67ac4c-1f7d-4777-b78e-5dd974b9b0c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Prompt ---\n",
            "\n",
            "This is the response from the previous prompt: <The Harvard Study of Adult Development, spanning 75 years and involving 724 men, reveals that good relationships are key to happiness and health, not wealth or fame. The study found that social connections improve physical health and increase longevity, while loneliness has the opposite effect. Quality, not quantity, of relationships matters, with supportive environments proving beneficial and high-conflict situations being detrimental to health. The study’s strongest predictor of a happy, healthy old age was satisfaction in relationships at age 50.\n",
            "----\n",
            "Гарвардское исследование взрослой жизни, продолжавшееся 75 лет и охватившее 724 мужчин, показывает, что хорошие отношения являются ключом к счастью и здоровью, а не богатство или слава. Исследование показало, что социальные связи улучшают физическое здоровье и увеличивают продолжительность жизни, в то время как одиночество имеет противоположный эффект. Важно не количество отношений, а их качество, при этом поддерживающая среда оказывается полезной, а конфликтные ситуации вредны для здоровья. Самым сильным предиктором счастливой и здоровой старости было удовлетворение отношениями в возрасте 50 лет.> \n",
            "Now take the Russian response and edit it into bullet points. \n",
            "Provide just the Russian bullet points.\n",
            "\n",
            "--- Answer ---\n",
            "\n",
            "- Гарвардское исследование взрослой жизни, продолжавшееся 75 лет и охватившее 724 мужчин, показывает, что хорошие отношения являются ключом к счастью и здоровью, а не богатство или слава.\n",
            "- Исследование показало, что социальные связи улучшают физическое здоровье и увеличивают продолжительность жизни, в то время как одиночество имеет противоположный эффект.\n",
            "- Важно не количество отношений, а их качество, при этом поддерживающая среда оказывается полезной, а конфликтные ситуации вредны для здоровья.\n",
            "- Самым сильным предиктором счастливой и здоровой старости было удовлетворение отношениями в возрасте 50 лет.\n"
          ]
        }
      ],
      "source": [
        "question = f\"\"\"This is the response from the previous prompt: <{original_answer}> \n",
        "Now take the Russian response and edit it into bullet points. \n",
        "Provide just the Russian bullet points.\"\"\"\n",
        "\n",
        "original_answer = pipeline(video_url, question)\n",
        "\n",
        "print(original_answer)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
